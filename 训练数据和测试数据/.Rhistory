##tp
myvar <- ls(pattern = "*.nc")
myvar
tp <- uvb.nc
myframe <-matrix(NA,0,3)###计算的是4-10月7个月的平均
tp
####
print(ls(pattern = "*.nc"))
##tp
myvar <- ls(pattern = "*.nc")
tp <- uvb.nc
myframe <-matrix(NA,0,3)###计算的是4-10月7个月的平均
for (j in 1:nrow(siteall)){
tp.sub <- data.frame(matrix(nrow=length(nc.file$time),ncol=1))
a <- tp[which(lon==siteall$lon[j]),which(lat==siteall$lat[j]),]##提取特定经纬度tp
tp.sub<- a ###写入矩阵
tpdata <- as.data.frame(cbind(time,tp.sub))
datetime<-as.data.frame(as.POSIXct.numeric(tpdata$time*3600, origin = "1900-01-01 00:00:00.0"))##CST
names(datetime) <- c('datetime')
tpdata$datetime <- datetime
location <- data.frame(lon=siteall$lon[j],lat=siteall$lat[j])
tpframesum <- apply(tpdata[c(2)],2,mean)-273.15
tpframesum2 <- cbind(location,tpframesum)
myframe <- rbind(myframe,tpframesum2)
# 进度条
pb$tick()
Sys.sleep(1/nrow(siteall))
}
datetime
rm(list=ls())
name.nc <- 'D:\\machine\\ypproject\\surface_ssr_f.nc'
nc.file <- nc_open(name.nc)
print(nc.file)
var.name <- ls(nc.file$var)
###读lon lat time 查看time
lat <- ncvar_get(nc.file, varid = "latitude")
lon <- ncvar_get(nc.file,varid = "longitude")
time <- ncvar_get(nc.file,varid = "time")
datetime <- as.data.frame(as.POSIXct.numeric(time*3600, origin = "1900-01-01 00:00:00.0"))##CST
datetime
buff <- nc_open(name.nc)
for (i in 1:length(var.name)) {
assign(paste(var.name[i],'nc',sep = '.'),
as.numeric(ncvar_get(buff,varid = var.name[i])))
}
###
var.var <- var.name[1:length(var.name)]
var.var
for (j in 1:length(var.var)) {
# 自动定义变量并赋值
eval(parse(
text = paste(paste(var.var[j],'nc',sep = '.'),
'<-',
'ncvar_get(buff,varid = var.var[j])',
sep = ' ')
))
}
####
print(ls(pattern = "*.nc"))
siteall <- merge(lon,lat)
names(siteall) <- c("lon","lat")
###进度条
pb <- progress_bar$new(
format = '数据提取进度 [:bar] :percent 剩余时间: :eta',
total = nrow(siteall), clear = TRUE, width= 60)
###
dim.var <- var.name[1:length(var.name)]
buff <- nc_open(name.nc[1])
for (i in 1:length(dim.var)) {
assign(paste(var.name[i],'nc',sep = '.'),
ncvar_get(buff,varid = dim.var[i]))
}
##tp
myvar <- ls(pattern = "*.nc")
tp <- uvb.nc
myframe <-matrix(NA,0,3)###计算的是4-10月7个月的平均
for (j in 1:nrow(siteall)){
tp.sub <- data.frame(matrix(nrow=length(nc.file$time),ncol=1))
a <- tp[which(lon==siteall$lon[j]),which(lat==siteall$lat[j]),]##提取特定经纬度tp
tp.sub<- a ###写入矩阵
tpdata <- as.data.frame(cbind(time,tp.sub))
datetime<-as.data.frame(as.POSIXct.numeric(tpdata$time*3600, origin = "1900-01-01 00:00:00.0"))##CST
names(datetime) <- c('datetime')
tpdata$datetime <- datetime
location <- data.frame(lon=siteall$lon[j],lat=siteall$lat[j])
tpframesum <- apply(tpdata[c(2)],2,mean)-273.15
tpframesum2 <- cbind(location,tpframesum)
myframe <- rbind(myframe,tpframesum2)
# 进度条
pb$tick()
Sys.sleep(1/nrow(siteall))
}
names(myframe) <- c("lon","lat","mean_1319.uvb")
head(myframe)
write.csv(myframe,"D:\\grids\\uvb_13_20_f.csv",row.names = F)
df_map <- readOGR(dsn="D:\\Rclass\\cm",layer = "bou2_4p")
data <- myframe
#read.csv("D:\\grids\\t2m_13_20_全年.csv")
summary(data)
a <- classIntervals(data$mean.t2m, 8)###等频分割
breaks_lines <- c(-5,0,5,10,15,20,22,24,32)
data$mybreak2 <- cut(data$mean.t2m,breaks_lines)
a <- classIntervals(data$mean_1319.uvb, 8)###等频分割
breaks_lines <- c(-5,0,5,10,15,20,22,24,32)
data$mybreak2 <- cut(data$mean.t2m,breaks_lines)
data$mybreak2 <- cut(data[c(3)],breaks_lines)
data$mybreak2 <- cut(data[,3],breaks_lines)
a <- classIntervals(data[,3], 8)###等频分割
breaks_lines <- c(-5,0,5,10,15,20,22,24,32)
data$mybreak2 <- cut(data[,3],breaks_lines)
data$mybreak3 <- as.numeric(str_sub(data$mybreak2,2,str_locate(data$mybreak2,",")[,1]-1))
table(data$mybreak3)
head(data)
str(data)
n <- length(breaks_lines)
a
###距平计
ｍｙ <- ２
####plot
df_map <- readOGR(dsn="D:\\Rclass\\cm",layer = "bou2_4p")
###距平计
ｍｙ <- ２
####plot
df_map <- readOGR(dsn="D:\\Rclass\\cm",layer = "bou2_4p")
###距平计
ｍｙ <- ２
####plot
df_map <- readOGR(dsn="D:\\Rclass\\cm",layer = "bou2_4p")
dim(mydata)
mydata <- read.csv("D:\\machine\\data\\ozone\\metadjustment\\data1320.csv")
dim(mydata)
head(mydata)
library(Matrix)
library(xgboost)
library(breakDown)
library(pROC)
library(randomForest)
library(DALEX)
####使用xgboots预测ambient臭氧浓度
mydata <- read.csv("D:\\machine\\data\\ozone\\metadjustment\\data1320.csv")
mydata$year <- as.numeric(substr(mydata$date,1,4))
mydata$month <- as.numeric(substr(mydata$date,5,6))
mydata$day <- as.numeric(substr(mydata$date,7,8))
mydata2 <- mydata[c(-3,-10)]
train_sub <- sample(nrow(mydata2),3/10*nrow(mydata2))###随机排序
train_data <- mydata2[train_sub,]
test_data <- mydata2[-train_sub,]
##训练集数据预处理
traindata1 <- data.matrix(train_data[,c(-8)])
traindata2 <- Matrix(traindata1,sparse = T)##转化成稀疏矩阵
traindata3 <- train_data[,8]
###自变量和因变量集合成list
traindata4 <- list(data=traindata2,label=traindata3)
###构造需要的xgb.Dmatrix对象，处理对象为稀疏矩阵
dtrain <- xgb.DMatrix(data=traindata4$data,label=traindata4$label)
#必要的参数进行设置，并开始建模
param <- list(max_depth = 2, eta = 1, silent = 1, nthread = 2, objective = "reg:linear")
##
explainer_xgb <- explain(wine_xgb_model,data = model_martix_train,y = wine$quality,label = "xgboost")
###
###测试集的数据预处理
#自变量转变成矩阵
testset1 <- data.matrix(test_data[,c(-8)])
###转换成稀疏矩阵
testset2 <- Matrix(testset1,sparse = T)
##讲因变量转成numeric
testset3 <- test_data[,8]
##自变量和因变量拼接成list
testset4 <- list(data=testset2,label=testset3)
##构造模型需要的xgb.Dmatrix对象，处理对象为稀疏矩阵
dtest <- xgb.DMatrix(data=testset4$data,label=testset4$label)
##构建xgboots模型
xgb <- xgboost(data=dtrain,max_depth=6,eta=0.5,objextive='binary:logistic',nround=25)
##在测试集上预测
pre_xgb <- predict(xgb,newdata = dtest)
##输出混淆矩阵
#table(test_data$ambient,pre_xgb,dnn=c("真实值","预测值"))
dbdata<- data.frame(ambient=test_data$ambient,predict=pre_xgb)
coor <- cor(dbdata$ambient,dbdata$predict)
corrplot::corrplot()
##绘制roc
xgboost_roc <- roc(test_data$ambient,as.numeric(pre_xgb))
plot(xgboost_roc,print.auc=TRUE,auc.polygon=TRUE,grid=c(0.1,0.2),grid.col=c("green","red"),max.auc.polygon=TRUE,auc.polygon.col="skyblue",print.thres=TRUE,main="xgboots model ROC curve ")
train_data <- read.table("D:\\machine\\data\\ozone\\metadjustment\\train_data1320.csv",sep=",",header = T)
test_data <- read.table("D:\\machine\\data\\ozone\\metadjustment\\test_data1320.csv",sep=",",header = T)
str(train_data)
train_data2 <- train_data[1:10000,]
t1 <- proc.time()
mydata2_randomforest2 <- randomForest(ambient ~.,
data = train_data2,
ntree =200,
mtry=3,
nodesize=5,
importance=F,
proximity=F)
proc.time()-t1
pre_ran <- predict(mydata2_randomforest2,newdata=test_data)
obs_p_ran <- data.frame(prob=pre_ran,obs=test_data$ambient)
cor(obs_p_ran)
#数据预处
library(randomForest)
library(foreach)
library(parallel)
library(doParallel)
train_data <- read.table("D:\\machine\\data\\ozone\\metadjustment\\train_data1320.csv",sep=",",header = T)
test_data <- read.table("D:\\machine\\data\\ozone\\metadjustment\\test_data1320.csv",sep=",",header = T)
str(train_data)
train_data2 <- train_data[1:10000,]
t1 <- proc.time()
mydata2_randomforest2 <- randomForest(ambient ~.,
data = train_data2,
ntree =200,
mtry=3,
nodesize=5,
importance=F,
proximity=F)
proc.time()-t1
pre_ran <- predict(mydata2_randomforest2,newdata=test_data)
obs_p_ran <- data.frame(prob=pre_ran,obs=test_data$ambient)
cor(obs_p_ran)
####
cl <- makeCluster(4)
registerDoParallel(cl)
t1 <- proc.time()
rf <- foreach(ntree=rep(50,4),.combine ="combine",.packages = 'randomForest') %dopar% {
randomForest(ambient ~.,
data = train_data2,
ntree =ntree,
mtry=3,
nodesize=5,
importance=F,
proximity=F)}
stopCluster(cl)
proc.time()-t1
pre_ran <- predict(rf,newdata=test_data)
pre_ran2 <- predict(rf,newdata=test_data)
obs_p_ran2 <- data.frame(prob=pre_ran2,obs=test_data$ambient)
cor(obs_p_ran)
cor(obs_p_ran2)
pre_ran <- predict(mydata2_randomforest2,newdata=test_data)
obs_p_ran <- data.frame(prob=pre_ran,obs=test_data$ambient)
cor(obs_p_ran)
class(mydata2_randomforest2)
class(rf)
rf
t1 <- proc.time()
rf <- foreach(ntree=rep(50,5),.combine ="combine",.packages = 'randomForest') %dopar% {
randomForest(ambient ~.,
data = train_data2,
ntree =ntree,
mtry=3,
nodesize=5,
importance=F,
proximity=F)}
stopCluster(cl)
proc.time()-t1
cl <- makeCluster(4)
registerDoParallel(cl)
t1 <- proc.time()
rf <- foreach(ntree=rep(50,5),.combine ="combine",.packages = 'randomForest') %dopar% {
randomForest(ambient ~.,
data = train_data2,
ntree =ntree,
mtry=3,
nodesize=5,
importance=F,
proximity=F)}
stopCluster(cl)
proc.time()-t1
pre_ran2 <- predict(rf,newdata=test_data)
obs_p_ran2 <- data.frame(prob=pre_ran2,obs=test_data$ambient)
cor(obs_p_ran2)
cor(obs_p_ran)
rf
t1 <- proc.time()
mydata2_randomforest2 <- randomForest(ambient ~.,
data = train_data2,
ntree =200,
mtry=3,
nodesize=5,
importance=T,
proximity=F)
proc.time()-t1
pre_ran <- predict(mydata2_randomforest2,newdata=test_data)
obs_p_ran <- data.frame(prob=pre_ran,obs=test_data$ambient)
cor(obs_p_ran)
cl <- makeCluster(4)
registerDoParallel(cl)
t1 <- proc.time()
rf <- foreach(ntree=rep(50,10),.combine ="combine",.packages = 'randomForest') %dopar% {
randomForest(ambient ~.,
data = train_data2,
ntree =ntree,
mtry=3,
nodesize=5,
importance=T,
proximity=F)}
stopCluster(cl)
proc.time()-t1
pre_ran2 <- predict(rf,newdata=test_data)
obs_p_ran2 <- data.frame(prob=pre_ran2,obs=test_data$ambient)
cor(obs_p_ran2)
rf
t1 <- proc.time()
mydata2_randomforest2 <- randomForest(ambient ~.,
data = train_data2,
ntree =500,
mtry=3,
nodesize=5,
importance=T,
proximity=F)
proc.time()-t1
write.csv(train_data2,"D:\\machine\\data\\ozone\\metadjustment\\train_data1320_2.csv",row.names =F)
getwd()
d1 <- read.csv("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\china_sites_20200406.csv",header=T)
d2 <- read.csv("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\china_sites_20200507.csv",header=T)
d3 <- read.csv("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\china_sites_20201206.csv",header=T)
d4 <- read.csv("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\china_sites_20201231.csv",header=T)
Xall <- intersect(intersect(intersect(d2$X,d1$X),d3$X),d4$X)
d1x<- subset(d1,d1$X%in%Xall)
d2x <- subset(d2,d2$X%in%Xall)
d3x <- subset(d3,d3$X%in%Xall)
d4x <- subset(d4,d4$X%in%Xall)
mydata2020 <- cbind(d1x,d2x,d3x,d4x)
View(mydata2020)
names(site) <- c("code","lon","lat")
###1-96 1644
##97-128 1660
##129-366 1673
site <- read.csv("D:\\桌面\\全国空气质量\\_站点列表\\站点列表-2020.01.01起.csv",sep=",",fileEncoding = "UTF-8",header =T)
names(site) <- c("code","lon","lat")
num <- paste0("X",site$code)
site2
site2 <- unique(data.frame(num,site[,-1]))
site2
View(site2)
X <- paste0("X",site$code)
site2 <- unique(data.frame(X,site[,-1]))
site2
xx <- merge(site2,mydata2020)
names(mydata2020)
colnames(mydata2020)
colnames(site2)
xx <- merge(site2,mydata2020,by="X")
###1-96 1644
##97-128 1660
##129-366 1673
site <- read.csv("D:\\桌面\\全国空气质量\\_站点列表\\站点列表-2020.01.01起.csv",sep=",",fileEncoding = "UTF-8",header =T)
head(site)
names(site) <- c("code","name","city","lon","lat")
X <- paste0("X",site$code)
site2 <- unique(data.frame(X,site[,-1]))
site2
head(site2)
head(mydata2020)
xx <- merge(site2,mydata2020,by="X")
xx <- merge(site2,mydata2020)
colnames(mydata2020) <- mydata2020[1,]
mydata2020 <- mydata2020[-1,]
mydata2020 <- cbind(d1x,d2x,d3x,d4x)
View(mydata2020)
colnames(mydata2020) <- mydata2020[1,]
mydata2020 <- mydata2020[3:nrow(mydata2020),]
mydata2020 <- cbind(d1x,d2x,d3x,d4x)
View(mydata2020)
colnames(mydata2020) <- mydata2020[1,]
mydata2020_2 <- mydata2020[4:nrow(mydata2020),]
View(mydata2020_2)
mydata2020 <- mydata2020[4:nrow(mydata2020),]
colnames(mydata2020$date) <- c("X")
colnames(mydata2020[c(1)]) <- c("X")
colnames(mydata2020)
mydata2020 <- cbind(d1x,d2x,d3x,d4x)
View(mydata2020)
colnames(mydata2020) <- mydata2020[1,]
mydata2020 <- mydata2020[4:nrow(mydata2020),]
mydata2020$X <- mydata2020$date
xx <- merge(site2,mydata2020,by=c("X"))
View(xx)
xxx <- melt(xx,id=c("X","lon","lat"))
xxx <- reshape2::melt(xx,id=c("X","lon","lat"))
View(xxx)
names(xxx) <- c("num","lon","lat","date","ma")
xxx <- xxx[order(xxx$num,xxx$date),]
View(xxx)
as.numeric(xxx$date)
character.as.numeric(xxx$date)
xxx$date
str(xxx)
as.character(xxx$date)
as.numeri(cas.character(xxx$date))
as.numeric(cas.character(xxx$date))
as.numeric(as.character(xxx$date))
xxx$date <- as.numeric(as.character(xxx$date))
xxx <- reshape2::melt(xx,id=c("X","lon","lat"))
names(xxx) <- c("num","lon","lat","date","ma")
xxx$date <- as.numeric(as.character(xxx$date))
xxx <- na.omit(xxx)
View(xxx)
write.csv(xxx,paste0("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\2020MDA8_1638site.csv"),col.names = F)
write.csv(xxx,paste0("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\2020MDA8_1638site.csv"),colnames = F)
write.csv(xxx,paste0("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\2020MDA8_1638site.csv"),row.names = F)
View(xxx)
View(xxx)
summary(xxx)
class(xxx)
max(xxx$ma)
str(xxx)
xxx$ma <- as.numeric(xxx$ma)
View(xxx)
write.csv(xxx,paste0("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\2020MDA8_1638site.csv"),row.names = F)
rm(list=ls())
library(Matrix)
library(xgboost)
library(breakDown)
library(pROC)
library(randomForest)
library(DALEX)
library(Metrics)
####划分训练数据和测试数据
setwd('D:/machine/data/训练数据和测试数据/')
dataset <- na.omit(read.csv('Mydata_train_prd_13-17.csv'))
###随机排序 20%测试
train_sub <- sample(nrow(dataset),2/10*nrow(dataset))
train_data <- dataset[train_sub,]
test_data <- dataset[-train_sub,]
##训练集数据预处理
traindata1 <- data.matrix(train_data[,c(-4)])###去掉要预测的特征
traindata2 <- Matrix(traindata1,sparse = T)##转化成稀疏矩阵
traindata3 <- train_data[,4]#预测的特征
###自变量和因变量集合成list
traindata4 <- list(data=traindata2,label=traindata3)
###构造需要的xgb.Dmatrix对象，处理对象为稀疏矩阵
dtrain <- xgb.DMatrix(data=traindata4$data,label=traindata4$label)
#必要的参数进行设置，并开始建模
param <- list(max_depth = 2, eta = 1, silent = 1, nthread = 2, objective = "reg:linear")
###测试集的数据预处理
#自变量转变成矩阵
testset1 <- data.matrix(test_data[,c(-4)])
###转换成稀疏矩阵
testset2 <- Matrix(testset1,sparse = T)
##因变量转成numeric
testset3 <- test_data[,4]
##自变量和因变量拼接成list
testset4 <- list(data=testset2,label=testset3)
##构造模型需要的xgb.Dmatrix对象，处理对象为稀疏矩阵
dtest <- xgb.DMatrix(data=testset4$data,label=testset4$label)
##构建xgboots模型
xgb <- xgboost(data=dtrain,max_depth=6,eta=0.5,objextive='binary:logistic',nround=25)
#重要重要性排序
importance <- xgb.importance(traindata2@Dimnames[[2]], model = xgb)
head(importance)
xgb.ggplot.importance(importance)
##在测试集上预测
pre_xgb <- predict(xgb, dtest)
##输出混淆矩阵
#table(test_data$ambient,pre_xgb,dnn=c("真实值","预测值"))
dbdata<- data.frame(ambient=test_data$ma,predict=pre_xgb)
test.df <-cbind(test_data[,-4],dbdata)
####模型评价
Metrics::rmse(dbdata$ambient,dbdata$predict)#rmse
cor(dbdata$ambient,dbdata$predict)#r
###ssp气象+ssp排放预测
sspdata <- list.files('D:\\machine\\data\\训练数据和测试数据',pattern="2020_SSP*")
ozone2020 <- read.csv("D:\\桌面\\全国空气质量\\站点_20200101-20201231\\2020mda8\\2020MDA8_ozonesub_1034.csv")
ozone2020sub <- subset(ozone2020,ozone2020$lat>=20&ozone2020$lat<=26&ozone2020$lon>=109&ozone2020$lon<=118)##广东地区
##
ozone2020sub2 <- ozone2020sub[-which(ozone2020sub$ma==-999),]
library(plyr)
ozonemean2<- aggregate(ozone2020sub2[c("ma")],by=list(lon=ozone2020sub2$lon,lat=ozone2020sub2$lat,month=substr(ozone2020sub2$date,1,6)),FUN='mean')
dim(unique(ozonemean2[c("lon","lat")]))
dim(unique(predictdata[c("lon","lat")]))
for(i in 1:6){
predictdata <- read.csv(paste0('D:\\machine\\data\\训练数据和测试数据\\',sspdata[i]))
predictdata <- predictdata[xgb$feature_names]
preset1 <- data.matrix(predictdata)
###转换成稀疏矩阵
preset2 <- Matrix(preset1,sparse = T)
##自变量和因变量拼接成list
preset4 <- list(data=preset2)
##构造模型需要的xgb.Dmatrix对象，处理对象为稀疏矩阵
dtest <- xgb.DMatrix(data=preset4$data)
pre_ran <- predict(xgb,newdata = dtest)
dbdata<- data.frame(predict=pre_ran)
predict.df <-cbind(predictdata,dbdata)
df.m <- merge(predict.df,ozonemean2,by=c("lon","lat","month"))
write.csv(df.m,paste0('D:\\machine\\data\\XGBresult\\xgb_',sspdata[i]),row.names = F)
}
###月均浓度整合
plotlist <- list.files('D:\\machine\\data\\XGBresult\\',pattern="xgb_*")
mymatrix <- matrix(0,12,0)
for(i in 1:6){
plotdata <- read.csv(paste0('D:\\machine\\data\\XGBresult\\',plotlist[i]))
ozonemean<- aggregate(plotdata[,-1:-2],by=list(month=plotdata$month),FUN='mean')
ozonemean2 <- ozonemean[c("predict","ma")]
colnames(ozonemean2) <- c(substr(plotlist[i],10,20),"ma")
mymatrix <- cbind(mymatrix,ozonemean2)
}
mymatrix <- mymatrix[unique(names(mymatrix))]
r.df <- data.frame(cor(mymatrix))
rmse(mymatrix$ma,mymatrix$`SSP1-26-BHE`)
rmse(mymatrix$ma,mymatrix$`SSP1-26-ECP`)
rmse(mymatrix$ma,mymatrix$`SSP2-45-ECP`)
rmse(mymatrix$ma,mymatrix$`SSP3-70-BAU`)
rmse(mymatrix$ma,mymatrix$`SSP4-60-BAU`)
rmse(mymatrix$ma,mymatrix$`SSP5-85-BHE`)
rdf[c(2)]
##画图
library(Ckmeans.1d.dp)
install.packages("Ckmeans.1d.dp")
library(Ckmeans.1d.dp)
xgb.ggplot.importance(importance)
